{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "We want to test the behavior of ProcessOptimizer on different model systems with\n",
    "different settings. First, we create a list of dicts, where each dict contains the\n",
    "settings to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from typing import Union\n",
    "\n",
    "from ProcessOptimizer.model_systems import get_model_system\n",
    "from ProcessOptimizer import Optimizer\n",
    "\n",
    "MODEL_SYSTEM_NAMES = [\n",
    "    \"branin_hoo\",\n",
    "    \"hart3\",\n",
    "    \"hart6\",\n",
    "]\n",
    "EXPERIMENT_BUDGET = 100 # How many evaluations we can do in total per optimization\n",
    "NUM_REPLICATIONS = 20 # How many times to perform each optimization\n",
    "NOISE_LEVELS = [0.0, 0.2, 1.0, 5.0, 10.0] # What to multiply the noise of the modelsystem by\n",
    "TARGET_LEVEL = [0.01, 0.1] # How close to the true minimum we want to get\n",
    "N_INITIAL_POINTS = [4, 10]\n",
    "\n",
    "seed = 0 # Seed for \"randomly\" making noise, ensures reproducibility\n",
    "tests : list[dict[str, Union[str, float, int]]] = [] # Consider making a \"test\" dataclass for better typing\n",
    "for model_system_name, relative_noise_level, n_initial_points, target_level in product(\n",
    "    MODEL_SYSTEM_NAMES,\n",
    "    NOISE_LEVELS,\n",
    "    N_INITIAL_POINTS,\n",
    "    TARGET_LEVEL\n",
    "):\n",
    "    for _ in range(NUM_REPLICATIONS): # Adding NUM_REPLICATIONS tests for each combination\n",
    "        seed += 1 # Each test should have a different seed\n",
    "        test = {\n",
    "            \"model_system_name\": model_system_name,\n",
    "            \"noise_level\": relative_noise_level,\n",
    "            \"n_initial_points\": n_initial_points,\n",
    "            \"target_level\": target_level,\n",
    "            \"experiment_budget\": EXPERIMENT_BUDGET,\n",
    "            \"seed\": seed\n",
    "        }\n",
    "        tests.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create the function to run the test on each member of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_optimization(\n",
    "        test: dict[str, Union[str, float, int]]\n",
    ") -> tuple[dict, int, bool]:\n",
    "    \"\"\"\n",
    "    Run an optimization test and return the number of evaluations done and whether the\n",
    "    optimization was successful\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test : dict\n",
    "        A dictionary containing the test parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing the input test (for reference), the number of evaluations done\n",
    "        and whether the optimization was successful.\n",
    "    \"\"\"\n",
    "    model_system = get_model_system(test[\"model_system_name\"], seed = test[\"seed\"])\n",
    "    model_system.noise_level = model_system.noise_level*test[\"noise_level\"]\n",
    "    range = model_system.true_max - model_system.true_min\n",
    "    target = model_system.true_min + test[\"target_level\"] * range\n",
    "    optimizer = Optimizer(\n",
    "        dimensions=test[\"model_system\"].space,\n",
    "        n_initial_points=test[\"n_initial_points\"]\n",
    "    )\n",
    "    for _ in range(test[\"experiment_budget\"]):\n",
    "        finished = False\n",
    "        x = optimizer.ask()\n",
    "        y = model_system(x)\n",
    "        if y < target:\n",
    "            # We have found a point that is close enough to the true minimum\n",
    "            # There should be some more logic here, to check if the point is acutally\n",
    "            # good enough, or whether it was just luck.\n",
    "            finished = True\n",
    "            break\n",
    "        optimizer.tell(x, y)\n",
    "        return (test, len(optimizer.Xi), finished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the tests in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "p = Pool(5)\n",
    "result = p.map(run_test_optimization, tests)\n",
    "p.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
